# plastic_featurizer.py
# å¡‘æ–™åˆ†å­ç‰¹å¾æå–å™¨ - æ™ºèƒ½å½’ä¸€åŒ–ç‰ˆæœ¬

import os
import logging
from typing import List, Dict, Optional, Tuple
import torch
import pandas as pd
import yaml
from rdkit import Chem
from rdkit.ML.Descriptors import MoleculeDescriptors
from rdkit.Chem import Descriptors, Fragments
from rdkit.Chem.rdPartialCharges import ComputeGasteigerCharges
from tqdm import tqdm

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class PlasticFeaturizer:
    """å¡‘æ–™åˆ†å­ç‰¹å¾æå–å™¨ - åŸºäºRDKitåˆ†å­æè¿°ç¬¦"""

    def __init__(self, config_path: Optional[str] = None):
        """åˆå§‹åŒ–ç‰¹å¾æå–å™¨"""
        self.config = self._load_config(config_path)
        self.normalize = self.config.get("normalize", True)

        # è·å–æè¿°ç¬¦åˆ—è¡¨
        self.standard_descriptors = self._get_standard_descriptors()
        self.fragment_descriptors = self._get_fragment_descriptors()
        self.charge_descriptors = self._get_charge_descriptors()

        # æ™ºèƒ½æ£€æŸ¥ï¼šå¦‚æœå¯ç”¨å½’ä¸€åŒ–ä½†ç”¨æˆ·æ²¡æœ‰é…ç½®HeavyAtomCountï¼Œç»™å‡ºæç¤º
        if self.normalize and 'HeavyAtomCount' not in self.standard_descriptors:
            logger.info("ğŸ¤– æ™ºèƒ½æ¨¡å¼ï¼šæ£€æµ‹åˆ°å½’ä¸€åŒ–å¼€å¯ä½†æœªé…ç½®HeavyAtomCountï¼Œå°†è‡ªåŠ¨è®¡ç®—")

        # åˆå§‹åŒ–RDKitè®¡ç®—å™¨
        if self.standard_descriptors:
            self.calculator = MoleculeDescriptors.MolecularDescriptorCalculator(self.standard_descriptors)
        else:
            self.calculator = None

        self._output_feature_names = None
        total_features = len(self.standard_descriptors) + len(self.fragment_descriptors) + len(self.charge_descriptors)

        logger.info(
            f"åˆå§‹åŒ–å®Œæˆ - æ ‡å‡†:{len(self.standard_descriptors)}, å®˜èƒ½å›¢:{len(self.fragment_descriptors)}, ç”µè·:{len(self.charge_descriptors)}")

    def _load_config(self, config_path: Optional[str]) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)
            except Exception as e:
                logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")

        # é»˜è®¤é…ç½®ï¼šä½¿ç”¨å…¨éƒ¨æ ‡å‡†æè¿°ç¬¦
        return {"normalize": True, "descriptor_names": None}

    def _get_standard_descriptors(self) -> List[str]:
        """è·å–æ ‡å‡†RDKitæè¿°ç¬¦"""
        all_descriptors = [desc[0] for desc in Descriptors._descList]
        descriptor_names = self.config.get("descriptor_names", [])

        # âœ… é»˜è®¤æ’é™¤çš„æè¿°ç¬¦ï¼ˆåªåœ¨ descriptor_names ä¸º None æˆ– [] æ—¶ç”Ÿæ•ˆï¼‰
        exclude_by_default = {"Ipc"}

        if descriptor_names is None or descriptor_names == []:
            filtered = [d for d in all_descriptors if d not in exclude_by_default]
            logger.info(
                f"descriptor_names ä¸º {descriptor_names}ï¼Œé»˜è®¤ä½¿ç”¨å…¨éƒ¨ RDKit æè¿°ç¬¦ï¼Œå·²æ’é™¤: {sorted(exclude_by_default)}")
            return filtered

        # âœ… æ˜¾å¼é…ç½®æ—¶ï¼Œä¸¥æ ¼æŒ‰ç”¨æˆ·è¦æ±‚ä¿ç•™ï¼Œå³ä½¿åŒ…å«ä¸æ¨èçš„ä¹Ÿä¸æ’é™¤
        return [d for d in descriptor_names if d in all_descriptors]

    def _get_fragment_descriptors(self) -> List[str]:
        """è·å–å®˜èƒ½å›¢æè¿°ç¬¦"""
        available_fragments = [
            'fr_ester', 'fr_amide', 'fr_ether', 'fr_benzene', 'fr_C_O',
            'fr_alkyl_halide', 'fr_ketone', 'fr_phenol', 'fr_nitrile'
        ]
        descriptor_names = self.config.get("descriptor_names", [])

        # å¤„ç†Noneçš„æƒ…å†µ
        if descriptor_names is None:
            return available_fragments

        return [d for d in descriptor_names if d in available_fragments]

    def _get_charge_descriptors(self) -> List[str]:
        """è·å–ç”µè·æè¿°ç¬¦"""
        available_charges = ['MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge']
        descriptor_names = self.config.get("descriptor_names", [])

        # å¤„ç†Noneçš„æƒ…å†µ
        if descriptor_names is None:
            return available_charges

        return [d for d in descriptor_names if d in available_charges]

    def featurize_mol(self, mol: Chem.Mol) -> Optional[torch.Tensor]:
        """ä»RDKit Molå¯¹è±¡æå–ç‰¹å¾å‘é‡"""
        try:
            all_values = {}

            # 1. æ ‡å‡†æè¿°ç¬¦
            if self.calculator and self.standard_descriptors:
                standard_values = self.calculator.CalcDescriptors(mol)
                all_values.update(dict(zip(self.standard_descriptors, standard_values)))

            # 2. æ™ºèƒ½å¤„ç†HeavyAtomCountï¼šå¦‚æœéœ€è¦å½’ä¸€åŒ–ä½†ç”¨æˆ·æ²¡æœ‰é…ç½®ï¼Œè‡ªåŠ¨è®¡ç®—
            if self.normalize and 'HeavyAtomCount' not in all_values:
                heavy_atom_count = Descriptors.HeavyAtomCount(mol)
                all_values['HeavyAtomCount'] = heavy_atom_count
                logger.info(f"è‡ªåŠ¨è®¡ç®—HeavyAtomCount = {heavy_atom_count}")

            # 3. å®˜èƒ½å›¢æè¿°ç¬¦
            for frag_name in self.fragment_descriptors:
                try:
                    frag_func = getattr(Fragments, frag_name)
                    all_values[frag_name] = frag_func(mol)
                except AttributeError:
                    all_values[frag_name] = 0

            # 4. ç”µè·æè¿°ç¬¦
            if self.charge_descriptors:
                try:
                    ComputeGasteigerCharges(mol)
                    charges = [float(atom.GetProp('_GasteigerCharge')) for atom in mol.GetAtoms()]
                    charges = [c for c in charges if not pd.isna(c)]

                    if charges:
                        if 'MaxPartialCharge' in self.charge_descriptors:
                            all_values['MaxPartialCharge'] = max(charges)
                        if 'MinPartialCharge' in self.charge_descriptors:
                            all_values['MinPartialCharge'] = min(charges)
                        if 'MaxAbsPartialCharge' in self.charge_descriptors:
                            all_values['MaxAbsPartialCharge'] = max(abs(c) for c in charges)
                    else:
                        for charge_desc in self.charge_descriptors:
                            all_values[charge_desc] = 0.0
                except:
                    for charge_desc in self.charge_descriptors:
                        all_values[charge_desc] = 0.0

            # 5. å¤„ç†NaNå€¼
            for k, v in all_values.items():
                if pd.isna(v):
                    all_values[k] = 0.0

            # 6. å¯†åº¦å½’ä¸€åŒ–
            if self.normalize:
                all_values = self._normalize_features(all_values)

            # 7. è®°å½•ç‰¹å¾åç§°
            if self._output_feature_names is None:
                self._output_feature_names = list(all_values.keys())

            return torch.tensor(list(all_values.values()), dtype=torch.float32)

        except Exception as e:
            logger.error(f"ç‰¹å¾è®¡ç®—å¤±è´¥: {e}")
            return None

    def _normalize_features(self, raw_values: Dict[str, float]) -> Dict[str, float]:
        """æ™ºèƒ½å¯†åº¦å½’ä¸€åŒ– - é»˜è®¤å½’ä¸€åŒ–æ‰€æœ‰ç‰¹å¾ï¼Œåªæ’é™¤ä¸éœ€è¦çš„"""
        heavy_atoms = raw_values.get("HeavyAtomCount")

        if heavy_atoms is None:
            raise ValueError("å½’ä¸€åŒ–æ¨¡å¼ä¸‹ç¼ºå°‘HeavyAtomCountï¼Œä»£ç é€»è¾‘é”™è¯¯")

        if heavy_atoms <= 0:
            logger.warning(f"å¼‚å¸¸çš„HeavyAtomCountå€¼: {heavy_atoms}ï¼Œä½¿ç”¨1ä½œä¸ºé»˜è®¤å€¼")
            heavy_atoms = 1

        norm_values = raw_values.copy()

        # ä¸éœ€è¦å½’ä¸€åŒ–çš„ç‰¹å¾ï¼ˆå·²ç»æ˜¯æ¯”ç‡ã€å¼ºåº¦æˆ–å†…åœ¨æ€§è´¨ï¼‰
        non_normalizable_features = {
            # æ¯”ç‡å’Œç™¾åˆ†æ¯”ç‰¹å¾ï¼ˆå·²ç»å½’ä¸€åŒ–ï¼‰
            "FractionCsp3",  # sp3ç¢³æ¯”ä¾‹ï¼ˆ0-1ï¼‰

            # å¼ºåº¦å‹ç‰¹å¾ï¼ˆä¸éšåˆ†å­å¤§å°çº¿æ€§å˜åŒ–ï¼‰
            "MolLogP",  # äº²è„‚æ€§
            "MolMR",  # åˆ†å­æŠ˜å°„ç‡
            "HallKierAlpha",  # æåŒ–ç‡å‚æ•°

            # ç”µè·ç‰¹å¾ï¼ˆå¼ºåº¦ï¼Œä¸æ˜¯æ€»é‡ï¼‰
            "MaxPartialCharge",
            "MinPartialCharge",
            "MaxAbsPartialCharge",
            "MinAbsPartialCharge",

            # å¤æ‚æ‹“æ‰‘æŒ‡æ•°ï¼ˆå·²è€ƒè™‘åˆ†å­å¤§å°ï¼‰
            "BalabanJ",  # BalabanæŒ‡æ•°
            "BertzCT",  # Bertzå¤æ‚åº¦
            "Ipc",  # ä¿¡æ¯å†…å®¹æŒ‡æ•°
            "Kappa1", "Kappa2", "Kappa3",  # åˆ†å­å½¢çŠ¶æŒ‡æ•°

            # è¿æ¥æ€§æŒ‡æ•°ï¼ˆå·²å½’ä¸€åŒ–ï¼‰
            "Chi0", "Chi0n", "Chi0v",
            "Chi1", "Chi1n", "Chi1v",
            "Chi2", "Chi2n", "Chi2v",
            "Chi3n", "Chi3v", "Chi4n", "Chi4v",

            # æŒ‡çº¹å¯†åº¦ç‰¹å¾ï¼ˆå·²ç»æ˜¯å¯†åº¦ï¼‰
            "FpDensityMorgan1", "FpDensityMorgan2", "FpDensityMorgan3",

            # ç‰¹æ®Šæƒ…å†µ
            "HeavyAtomCount",  # ç”¨ä½œå½’ä¸€åŒ–åŸºå‡†ï¼Œæœ¬èº«ä¸å½’ä¸€åŒ–
        }

        # å¯¹æ‰€æœ‰å…¶ä»–ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–
        for feature_name, feature_value in raw_values.items():
            if feature_name not in non_normalizable_features:
                density_name = feature_name + "Density"
                norm_values[density_name] = feature_value / heavy_atoms

        return norm_values

    def featurize_file(self, file_path: str) -> Optional[torch.Tensor]:
        """ä»æ–‡ä»¶æå–ç‰¹å¾ï¼ˆæ”¯æŒ.molå’Œ.sdfï¼‰"""
        try:
            file_ext = os.path.splitext(file_path)[1].lower()

            if file_ext == '.mol':
                mol = Chem.MolFromMolFile(file_path, removeHs=False)
            elif file_ext == '.sdf':
                supplier = Chem.SDMolSupplier(file_path, removeHs=False)
                mol = next(supplier) if supplier else None
            else:
                logger.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
                return None

            if mol is None:
                logger.warning(f"æ— æ³•è§£ææ–‡ä»¶: {file_path}")
                return None

            return self.featurize_mol(mol)

        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥ {file_path}: {e}")
            return None

    def featurize_folder(self, folder_path: str, show_progress: bool = True) -> Tuple[Dict[str, torch.Tensor], Dict]:
        """æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„åˆ†å­æ–‡ä»¶"""
        if not os.path.isdir(folder_path):
            raise ValueError(f"ç›®å½•ä¸å­˜åœ¨: {folder_path}")

        mol_files = [f for f in os.listdir(folder_path) if f.endswith(('.mol', '.sdf'))]
        if not mol_files:
            raise ValueError(f"ç›®å½•ä¸­æ²¡æœ‰åˆ†å­æ–‡ä»¶: {folder_path}")

        feature_dict = {}
        failed_files = []

        iterator = tqdm(mol_files, desc="æå–ç‰¹å¾") if show_progress else mol_files

        for fname in iterator:
            file_path = os.path.join(folder_path, fname)
            features = self.featurize_file(file_path)

            if features is not None:
                name = os.path.splitext(fname)[0]
                feature_dict[name] = features
            else:
                failed_files.append(fname)

        stats = {
            "total_files": len(mol_files),
            "successful": len(feature_dict),
            "failed": len(failed_files),
            "failed_files": failed_files,
            "feature_dim": len(features) if features is not None else 0
        }

        logger.info(f"ç‰¹å¾æå–å®Œæˆ: {stats['successful']}/{stats['total_files']} æˆåŠŸ")
        return feature_dict, stats

    def save_features(self, feature_dict: Dict[str, torch.Tensor], output_prefix: str):
        """ä¿å­˜ç‰¹å¾åˆ°CSVå’ŒPyTorchæ–‡ä»¶"""
        if not feature_dict:
            raise ValueError("ç‰¹å¾å­—å…¸ä¸ºç©º")

        # ä¿å­˜CSV
        csv_path = f"{output_prefix}.csv"
        data_dict = {name: features.tolist() for name, features in feature_dict.items()}
        df = pd.DataFrame(data_dict).T

        if self._output_feature_names and len(self._output_feature_names) == df.shape[1]:
            df.columns = self._output_feature_names
        else:
            df.columns = [f"feature_{i}" for i in range(df.shape[1])]

        df.index.name = "plastic"
        df.to_csv(csv_path)

        # ä¿å­˜PyTorchæ–‡ä»¶
        pt_path = f"{output_prefix}.pt"
        save_dict = {
            "features": feature_dict,
            "feature_names": self._output_feature_names,
            "config": self.config,
            "num_features": len(self._output_feature_names) if self._output_feature_names else 0
        }
        torch.save(save_dict, pt_path)

        logger.info(f"ç‰¹å¾ä¿å­˜å®Œæˆ: {csv_path}, {pt_path}")
        return csv_path, pt_path

    def get_feature_names(self) -> Optional[List[str]]:
        """è·å–ç‰¹å¾åç§°åˆ—è¡¨"""
        return self._output_feature_names

    @classmethod
    def load_features(cls, pt_path: str) -> Dict:
        """åŠ è½½ä¿å­˜çš„ç‰¹å¾æ•°æ®"""
        return torch.load(pt_path, map_location='cpu')


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # æµ‹è¯•ç”¨çš„è¾“å…¥è¾“å‡ºè·¯å¾„
    INPUT_DIR = "/Users/shulei/PycharmProjects/Plaszyme/plastic/mols_for_unimol_10_sdf_new"  # æ‚¨çš„SDF/MOLæ–‡ä»¶å¤¹
    CONFIG_PATH = "/Users/shulei/PycharmProjects/Plaszyme/plastic/mol_features/rdkit_features.yaml"  # é…ç½®æ–‡ä»¶
    OUTPUT_PREFIX = "/Users/shulei/PycharmProjects/Plaszyme/test/outputs/all_description_new_less"  # è¾“å‡ºå‰ç¼€

    print("ğŸ§ª å¼€å§‹æµ‹è¯•å¡‘æ–™ç‰¹å¾æå–å™¨...")

    try:
        # åˆå§‹åŒ–æå–å™¨
        extractor = PlasticFeaturizer(CONFIG_PATH)

        # å¤„ç†æ–‡ä»¶å¤¹
        if os.path.exists(INPUT_DIR):
            features, stats = extractor.featurize_folder(INPUT_DIR)

            # ä¿å­˜ç»“æœ
            os.makedirs(os.path.dirname(OUTPUT_PREFIX), exist_ok=True)
            csv_path, pt_path = extractor.save_features(features, OUTPUT_PREFIX)

            # è¾“å‡ºç»“æœ
            print(f"\nâœ… æµ‹è¯•å®Œæˆ!")
            print(f"å¤„ç†: {stats['successful']}/{stats['total_files']} ä¸ªæ–‡ä»¶")
            print(f"ç‰¹å¾ç»´åº¦: {stats['feature_dim']}")
            print(f"è¾“å‡ºæ–‡ä»¶: {csv_path}, {pt_path}")

            if stats['failed_files']:
                print(f"âš ï¸  å¤±è´¥æ–‡ä»¶: {stats['failed_files']}")

            # å¿«é€ŸéªŒè¯
            loaded = PlasticFeaturizer.load_features(pt_path)
            print(f"éªŒè¯åŠ è½½: {len(loaded['features'])} ç§å¡‘æ–™ç‰¹å¾")

        else:
            print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {INPUT_DIR}")
            print("è¯·ä¿®æ”¹INPUT_DIRä¸ºæ‚¨çš„SDFæ–‡ä»¶å¤¹è·¯å¾„")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()