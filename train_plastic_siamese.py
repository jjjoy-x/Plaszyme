import os
import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import itertools
from torch.utils.data import Dataset, DataLoader
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import umap
import matplotlib.pyplot as plt
import imageio
import cv2
from fpdf import FPDF

from plastic.mol_features.descriptors_rdkit import PlasticFeaturizer

# ===================== ç”¨æˆ·é…ç½® =====================
RUN_NAME = "run/run_from_sdf_7"
SDF_DIR = "/Users/shulei/PycharmProjects/Plaszyme/plastic/mols_for_unimol_10_sdf_new"
CONFIG_PATH = "/Users/shulei/PycharmProjects/Plaszyme/plastic/mol_features/rdkit_features.yaml"
CO_MATRIX_CSV = "/Users/shulei/PycharmProjects/Plaszyme/test/outputs/plastic_co_matrix.csv"

LOSS_MODE = "contrastive" #"mse" æˆ– "contrastive"
MARGIN = 1.5
SIM_THRESHOLD = 0.01
BATCH_SIZE = 16
EPOCHS = 500
LR = 1e-4
PLOT_INTERVAL = 5
REDUCTION_METHOD = "tsne" # é™ç»´æ–¹å¼å¯é€‰: "pca", "umap", "tsne"

# ===================== è‡ªåŠ¨è·¯å¾„ç®¡ç† =====================
OUTDIR = os.path.join(RUN_NAME)
PLOT_DIR = os.path.join(OUTDIR, "embedding_plots")
GIF_PATH = os.path.join(OUTDIR, "embedding_evolution.gif")
VIDEO_PATH = os.path.join(OUTDIR, "embedding_evolution.mp4")
PDF_PATH = os.path.join(OUTDIR, "embedding_snapshots.pdf")
LOSS_PATH = os.path.join(OUTDIR, "loss_curve.png")
MODEL_PATH = os.path.join(OUTDIR, "siamese_model.pt")
FEATURE_CSV = os.path.join(OUTDIR, "features.csv")
INFO_PATH = os.path.join(OUTDIR, "run_info.txt")

os.makedirs(PLOT_DIR, exist_ok=True)

# ===================== ç‰¹å¾æå– =====================
print("ğŸ§ª æ­£åœ¨æå–SDFç‰¹å¾...")
featurizer = PlasticFeaturizer(CONFIG_PATH)
feature_dict, stats = featurizer.featurize_folder(SDF_DIR)

# è‡ªåŠ¨ä¿å­˜åŒ…å«åˆ—åçš„ CSV å’Œ .pt æ–‡ä»¶
output_prefix = FEATURE_CSV.replace(".csv", "")
featurizer.save_features(feature_dict, output_prefix)

# è¯»å– CSVï¼ˆå¸¦åˆ—åï¼‰
features_df = pd.read_csv(FEATURE_CSV, index_col=0)
print(f"âœ… ç‰¹å¾ä¿å­˜è‡³ {FEATURE_CSV}")
print(f"ğŸ’¡ ç‰¹å¾ç»´åº¦: {features_df.shape[1]}ï¼Œå¡‘æ–™ç§ç±»: {features_df.shape[0]}")
print(f"ğŸ§¬ ç‰¹å¾åç¤ºä¾‹: {features_df.columns[:5].tolist()}")

# ===================== åŠ è½½å…±é™è§£çŸ©é˜µ =====================
co_matrix = pd.read_csv(CO_MATRIX_CSV, index_col=0)
features_df = features_df.loc[features_df.index.intersection(co_matrix.index)]
co_matrix = co_matrix.loc[features_df.index, features_df.index]
feature_dim = features_df.shape[1]

# ===================== æ„å»ºè®­ç»ƒå¯¹ =====================
data_pairs = []
for i, j in itertools.combinations(range(len(features_df)), 2):
    name_i = features_df.index[i]
    name_j = features_df.index[j]
    if name_i in co_matrix.index and name_j in co_matrix.columns:
        sim = co_matrix.loc[name_i, name_j]
        if pd.notna(sim):
            x1 = torch.tensor(features_df.loc[name_i].values, dtype=torch.float32)
            x2 = torch.tensor(features_df.loc[name_j].values, dtype=torch.float32)
            y = torch.tensor([1.0 if sim >= SIM_THRESHOLD else 0.0], dtype=torch.float32)
            data_pairs.append((x1, x2, y))

if not data_pairs:
    raise ValueError("âŒ æ— æœ‰æ•ˆè®­ç»ƒå¯¹")

print(f"âœ… æ„å»ºè®­ç»ƒå¯¹æ•°ï¼š{len(data_pairs)} å¯¹")

# ===================== Dataset =====================
class PairwiseDataset(Dataset):
    def __init__(self, pairs): self.pairs = pairs
    def __len__(self): return len(self.pairs)
    def __getitem__(self, idx): return self.pairs[idx]

# ===================== æ¨¡å‹å®šä¹‰ =====================
class SiameseRegressor(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64)
        )
    def forward_once(self, x): return self.encoder(x)
    def forward(self, x1, x2): return self.forward_once(x1), self.forward_once(x2)

class ContrastiveLoss(nn.Module):
    def __init__(self, margin): super().__init__(); self.margin = margin
    def forward(self, out1, out2, label):
        dist = torch.norm(out1 - out2, dim=1)
        loss = label.squeeze() * torch.pow(dist, 2) + \
               (1 - label.squeeze()) * torch.pow(torch.clamp(self.margin - dist, min=0.0), 2)
        return loss.mean()

def reduce_embeddings(embeddings, method="pca", random_state=42):
    if method == "pca":
        return PCA(n_components=2).fit_transform(embeddings)
    elif method == "umap":
        return umap.UMAP(n_components=2, random_state=random_state).fit_transform(embeddings)
    elif method == "tsne":
        return TSNE(n_components=2, random_state=random_state, perplexity=5).fit_transform(embeddings)
    else:
        raise ValueError(f"Unsupported reduction method: {method}")

# ===================== å¯è§†åŒ–å‡½æ•° =====================
def plot_embeddings(model, features_df, epoch, save_dir):
    model.eval()
    with torch.no_grad():
        X = torch.tensor(features_df.values, dtype=torch.float32)
        embeddings = model.encoder(X).numpy()
        reduced = reduce_embeddings(embeddings, method=REDUCTION_METHOD)

        plt.figure(figsize=(6, 5))
        for i, name in enumerate(features_df.index):
            plt.scatter(reduced[i, 0], reduced[i, 1])
            plt.text(reduced[i, 0], reduced[i, 1], name, fontsize=7)
        plt.title(f"{REDUCTION_METHOD.upper()} - Epoch {epoch}")
        plt.tight_layout()
        plt.savefig(os.path.join(save_dir, f"epoch_{epoch:03d}.png"))
        plt.close()

# ===================== è®­ç»ƒæµç¨‹ =====================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
dataloader = DataLoader(PairwiseDataset(data_pairs), batch_size=BATCH_SIZE, shuffle=True)
model = SiameseRegressor(feature_dim).to(device)
optimizer = optim.Adam(model.parameters(), lr=LR)
criterion = ContrastiveLoss(MARGIN)

print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
losses = []
for epoch in range(EPOCHS):
    model.train()
    total_loss = 0
    for x1, x2, y in dataloader:
        x1, x2, y = x1.to(device), x2.to(device), y.to(device)
        h1, h2 = model(x1, x2)
        loss = criterion(h1, h2, y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * x1.size(0)
    avg_loss = total_loss / len(dataloader.dataset)
    losses.append(avg_loss)
    if epoch % PLOT_INTERVAL == 0 or epoch == EPOCHS - 1:
        print(f"Epoch {epoch:03d} | Loss = {avg_loss:.5f}")
        plot_embeddings(model, features_df, epoch, PLOT_DIR)

# ===================== ç»“æœä¿å­˜ =====================
plt.figure()
plt.plot(range(EPOCHS), losses)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training Loss")
plt.tight_layout()
plt.savefig(LOSS_PATH)

imgs = [imageio.v2.imread(os.path.join(PLOT_DIR, f)) for f in sorted(os.listdir(PLOT_DIR)) if f.endswith(".png")]
imageio.mimsave(GIF_PATH, imgs, duration=0.8)

frame = cv2.imread(os.path.join(PLOT_DIR, sorted(os.listdir(PLOT_DIR))[0]))
height, width, _ = frame.shape
video = cv2.VideoWriter(VIDEO_PATH, cv2.VideoWriter_fourcc(*'mp4v'), 1.25, (width, height))
for f in sorted(os.listdir(PLOT_DIR)):
    if f.endswith(".png"):
        img = cv2.imread(os.path.join(PLOT_DIR, f))
        video.write(img)
video.release()

pdf = FPDF()
for f in sorted(os.listdir(PLOT_DIR)):
    if f.endswith(".png"):
        pdf.add_page()
        pdf.image(os.path.join(PLOT_DIR, f), x=10, y=10, w=180)
pdf.output(PDF_PATH)

torch.save(model.state_dict(), MODEL_PATH)
print(f"âœ… æ¨¡å‹ä¿å­˜è‡³: {MODEL_PATH}")

# ===================== æ¢¯åº¦åˆ†æ =====================
print("ğŸ” å¼€å§‹æ¢¯åº¦åˆ†æ...")

model.eval()
X_tensor = torch.tensor(features_df.values, dtype=torch.float32, requires_grad=True).to(device)
embeddings = model.encoder(X_tensor)  # [n_samples, embedding_dim]

# ä½¿ç”¨ç®€å•æ–¹å¼ï¼šè®¡ç®—æ¯ä¸ªæ ·æœ¬ä¸å¹³å‡ embedding çš„è·ç¦»å¹³æ–¹å’Œ
avg_embedding = embeddings.mean(dim=0, keepdim=True)
distances = torch.norm(embeddings - avg_embedding, dim=1).pow(2).sum()
distances.backward()

# è·å–æ¢¯åº¦
grads = X_tensor.grad.cpu().numpy()
avg_grad = grads.mean(axis=0)

# æ„å»º DataFrame ä¿å­˜
grad_df = pd.DataFrame({
    "feature": features_df.columns,
    "avg_gradient": avg_grad
})
grad_df["abs_gradient"] = grad_df["avg_gradient"].abs()
grad_df = grad_df.sort_values("abs_gradient", ascending=False)
grad_csv_path = os.path.join(OUTDIR, "feature_gradient_importance.csv")
grad_df.to_csv(grad_csv_path, index=False)
print(f"ğŸ“Š æ¢¯åº¦é‡è¦æ€§å·²ä¿å­˜è‡³: {grad_csv_path}")

# ç»˜åˆ¶å‰20ç‰¹å¾çš„æŸ±çŠ¶å›¾
top_n = 15
top_grad_df = grad_df.head(top_n)
plt.figure(figsize=(8, 5))
plt.barh(top_grad_df["feature"][::-1], top_grad_df["abs_gradient"][::-1])
plt.xlabel("Average Absolute Gradient")
plt.title(f"Top {top_n} Most Influential Features")
plt.tight_layout()
grad_plot_path = os.path.join(OUTDIR, "feature_gradient_barplot.png")
plt.savefig(grad_plot_path)
print(f"ğŸ“ˆ æ¢¯åº¦å›¾ä¿å­˜è‡³: {grad_plot_path}")