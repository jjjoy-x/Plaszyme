import torch
import torch.nn as nn
from torch_geometric.nn import global_mean_pool
from torch_geometric.data import Batch
from torch_geometric.nn import GCNConv, GATConv
from typing import Optional


class DeepFRIModel(nn.Module):
    """
    PyTorch Geometric å®ç°çš„ DeepFRI é£æ ¼æ¨¡å‹
    ----------------------------------------
    è¯¥æ¨¡å‹ç»“åˆ ESM è¡¨è¾¾çš„èŠ‚ç‚¹ç‰¹å¾ä¸å›¾ç¥ç»ç½‘ç»œï¼ˆå¦‚ GCN æˆ– GATï¼‰ï¼Œ
    ç”¨äºå›¾çº§åˆ«æˆ–æ®‹åŸºçº§åˆ«çš„è›‹ç™½è´¨åŠŸèƒ½é¢„æµ‹ã€‚
    """

    def __init__(
            self,
            gnn_type: str,
            gnn_dims: list[int],
            fc_dims: list[int],
            out_dim: int,
            dropout: float = 0.3,
            use_residue_level_output: bool = False,
            in_dim: Optional[int] = None,
    ):
        super(DeepFRIModel, self).__init__()
        self.in_dim = in_dim
        self.gnn_type_str = gnn_type.lower()
        self.gnn_dims = gnn_dims
        self.fc_dims = fc_dims
        self.out_dim = out_dim
        self.dropout_p = dropout
        self.use_residue_level_output = use_residue_level_output
        self._built = False

        # è‹¥å·²ç»™å®š in_dimï¼Œåˆ™ç«‹å³æ„å»º
        if self.in_dim is not None:
            self._build_layers(self.in_dim)

    def _get_gnn_layer(self, in_dim, out_dim):
        if self.gnn_type_str == 'gcn':
            return GCNConv(in_dim, out_dim)
        elif self.gnn_type_str == 'gat':
            return GATConv(in_dim, out_dim, heads=1, concat=False)  # ä¿æŒè¾“å‡ºç»´åº¦ä¸€è‡´
        else:
            raise ValueError(f"Unsupported GNN type: {self.gnn_type_str}")

    def _build_layers(self, detected_in_dim: int):
        if self.in_dim is None:
            self.in_dim = detected_in_dim
            print(f"[INFO] Auto-detected input dimension: {self.in_dim}")
        elif self.in_dim != detected_in_dim:
            print(f"[WARNING] Specified in_dim ({self.in_dim}) != input ({detected_in_dim}), using specified.")

        # GNN å †å 
        self.gnn_layers = nn.ModuleList()
        prev_dim = self.in_dim
        for out_dim in self.gnn_dims:
            self.gnn_layers.append(self._get_gnn_layer(prev_dim, out_dim))
            prev_dim = out_dim

        # è¯»å‡º + å…¨è¿æ¥
        self.readout = nn.Sequential(
            nn.Linear(sum(self.gnn_dims), self.fc_dims[0]),
            nn.ReLU(),
            nn.Dropout(self.dropout_p)
        )

        self.fc_layers = nn.ModuleList()
        for i in range(len(self.fc_dims) - 1):
            self.fc_layers.append(nn.Linear(self.fc_dims[i], self.fc_dims[i + 1]))
            self.fc_layers.append(nn.ReLU())
            self.fc_layers.append(nn.Dropout(self.dropout_p))

        self.output_layer = nn.Linear(self.fc_dims[-1], self.out_dim)
        self._built = True

    def forward(self, data: Batch) -> torch.Tensor:
        """
        Forward pass through GNN + Readout + Fully Connected layers
        å‰å‘ä¼ æ’­ï¼šGNN + Pooling + FC åˆ†ç±»
        """
        # æ‡’æ„å»ºï¼šç”¨è¾“å…¥è‡ªåŠ¨æ¨æ–­ç»´åº¦
        if not self._built:
            self._build_layers(data.x.size(-1))
            # ğŸ”‘ å…³é”®ï¼šæ–°å»ºå®Œçš„å±‚é»˜è®¤åœ¨ CPUï¼ŒæŠŠæ•´ä¸ªæ¨¡å‹è¿ç§»åˆ°è¾“å…¥æ‰€åœ¨è®¾å¤‡
            self.to(data.x.device)

        x, edge_index = data.x, data.edge_index

        # ä¿è¯ edge_index ä¸ x åœ¨åŒä¸€è®¾å¤‡ï¼ˆæœ‰äº›æ•°æ®çš„ edge_index ä»åœ¨ CPUï¼‰
        if edge_index.device != x.device:
            edge_index = edge_index.to(x.device)

        # æ²¡æœ‰ batch å±æ€§æ—¶ï¼Œè¡¥ä¸€ä¸ªï¼Œå¹¶æ”¾åˆ°åŒä¸€è®¾å¤‡
        if hasattr(data, 'batch') and data.batch is not None:
            batch = data.batch
            if batch.device != x.device:
                batch = batch.to(x.device)
        else:
            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)

        # é€å±‚ GNN
        gnn_outputs = []
        for layer in self.gnn_layers:
            x = layer(x, edge_index)
            gnn_outputs.append(x)

        # æ‹¼æ¥æ‰€æœ‰ GNN å±‚è¾“å‡º
        x = torch.cat(gnn_outputs, dim=-1)

        # æ®‹åŸºçº§è¾“å‡º
        if self.use_residue_level_output:
            return self.output_layer(x)  # [N, out_dim]

        # å›¾çº§ readout + FC
        x = global_mean_pool(x, batch)  # [B, hidden]
        x = self.readout(x)
        for layer in self.fc_layers:
            x = layer(x)
        return self.output_layer(x)  # [B, out_dim]

    def predict(self, data: Batch) -> torch.Tensor:
        """æ¨ç†æ¥å£ï¼Œè‡ªåŠ¨å…³é—­ dropout ä¸æ¢¯åº¦è®¡ç®—"""
        self.eval()
        with torch.no_grad():
            return self.forward(data)